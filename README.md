ğŸ“„ PDF QA Chatbot (RAG Demo)

A Python-based PDF Questionâ€“Answering chatbot built to understand and demonstrate the core concepts behind Retrieval-Augmented Generation (RAG).
This project allows users to upload a PDF document and ask natural language questions, with answers generated strictly from the document content.

ğŸš€ Project Overview

Large Language Models (LLMs) do not inherently â€œknowâ€ the content of private documents.
This project demonstrates how GenAI systems reason over documents by combining:

Document chunking

Embeddings

Vector similarity search

Context-aware prompting

LLM-based answer generation

The result is a simple but complete end-to-end RAG pipeline.

ğŸ§  What This Project Demonstrates

ğŸ“„ PDF ingestion and text extraction

âœ‚ï¸ Text chunking with overlap

ğŸ”¢ Embedding generation

ğŸ§  Vector storage using FAISS

ğŸ” Similarity-based retrieval

ğŸ’¬ Context-injected LLM prompting

ğŸ§¾ Answers grounded in document content (no hallucination)

This project was built as part of an Introduction to Generative AI learning journey to understand how modern document-based QA systems work under the hood.
```
ğŸ—‚ Project Structure
pdf-qa-chatbot-genai/
â”‚
â”œâ”€â”€ chatbot.py          # Main Streamlit application
â”œâ”€â”€ requirements.txt    # Project dependencies
â””â”€â”€ README.md           # Project documentation
```

ğŸ”„ How the System Works (High-Level Flow)

1ï¸âƒ£ User uploads a PDF document
2ï¸âƒ£ Text is extracted from all pages
3ï¸âƒ£ Text is split into overlapping chunks
4ï¸âƒ£ Each chunk is converted into vector embeddings
5ï¸âƒ£ Embeddings are stored in a FAISS vector database
6ï¸âƒ£ User asks a question
7ï¸âƒ£ Most relevant chunks are retrieved via similarity search
8ï¸âƒ£ Retrieved context is passed to the LLM
9ï¸âƒ£ LLM generates an answer grounded in the document

ğŸ›  Tech Stack

Python

Streamlit

LangChain

FAISS

OpenAI / Chat LLM

PyPDF2

â–¶ï¸ How to Run Locally
1ï¸âƒ£ Clone the repository

```
git clone https://github.com/naringrekarchinmay/pdf-qa-chatbot-genai.git
cd pdf-qa-chatbot-genai
```
2ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
```
3ï¸âƒ£ Set your API key
```
 export OPENAI_API_KEY="your-api-key"

```



4ï¸âƒ£ Run the app

```
streamlit run chatbot.py
```
ğŸ¯ Learning Outcomes

Through this project, I gained hands-on understanding of:

How LLMs interact with external knowledge

Why chunking and overlap matter

How embeddings enable semantic search

How vector databases power document retrieval

How RAG reduces hallucination in GenAI systems

ğŸ”® Future Improvements

Multi-document support

Source citation highlighting

Improved chunking strategies

Persistent vector storage

UI enhancements

Integration with more advanced LLMs

ğŸ“¬ About

This project was built as part of my Generative AI learning journey to strengthen my understanding of modern AI-powered document retrieval systems.

Feel free to explore, fork, or provide feedback!
